
@misc{richard_metas_2022,
	title = {Meta’s {Oculus} {Quest} 2 is the {Top} {Selling} {VR} {Headset} of 2021; {XR} {Market} {Growth} {Skyrockets}},
	url = {https://www.techtimes.com/articles/273303/20220321/meta-s-oculus-quest-2-top-selling-vr-headset-2021.htm},
	abstract = {Meta's Quest 2 VR Headset is the top selling in 2021 and it heavily borders towards the metaverse.},
	language = {en},
	urldate = {2022-06-30},
	journal = {Tech Times},
	author = {Richard, Isaiah},
	month = mar,
	year = {2022},
}

@misc{thiagarajan_is_2016,
	title = {Is the {Emotiv} {EPOC} signal quality good enough for research?},
	url = {https://sapienlabs.org/emotiv-epoc-signal-quality-good-enough-research/},
	abstract = {Share Tweet Share Pin Email The Emotiv EPOC at less than \$2000 opens up enormous possibilities to take research out of the lab to get […]},
	language = {en-US},
	urldate = {2022-06-29},
	journal = {Sapien Labs {\textbar} Neuroscience {\textbar} Human Brain Diversity Project},
	author = {Thiagarajan, Tara},
	month = dec,
	year = {2016},
}

@misc{cortechs_zip_nodate,
	title = {Zip and the {Misty} {Mountain} {Game} and {Neurosky} {Headset}},
	url = {https://www.cortechs.ie/product/zip-and-the-misty-mountain-game-and-neurosky-headset/},
	abstract = {Zip is a young apprentice on the Misty Mountain tasked with the challenge of racing to the head temple to wake the Master. Zip must leap over obstacles, gather glowing gems and clear the mist to wake the sleeping monks. Mastering concentration \& relaxation is key to unlocking Zips},
	language = {en-US},
	urldate = {2022-06-29},
	journal = {Cortechs Connect},
	author = {Cortechs},
}

@misc{neuromore_neuromore_nodate,
	type = {Documentation},
	title = {neuromore {Docs}},
	url = {https://doc.neuromore.com/},
	abstract = {neuromore Documentation.},
	urldate = {2022-06-29},
	journal = {neuromore Documentation},
	author = {Neuromore},
}

@misc{heater_snap_2022,
	title = {Snap buys mind-controlled headband maker {NextMind}},
	url = {https://social.techcrunch.com/2022/03/23/snap-buys-mind-controlled-headband-maker-nextmind/},
	abstract = {NextMind has joined Snap to help drive long-term augmented reality research efforts within Snap Lab.},
	language = {en-US},
	urldate = {2022-06-29},
	journal = {TechCrunch},
	author = {Heater, Brian},
	month = mar,
	year = {2022},
}

@misc{openbci_community_nodate,
	type = {Documentation},
	title = {Community {Page} {Projects} {\textbar} {OpenBCI} {Documentation}},
	url = {https://openbci.github.io/Examples/CommunityPageProjects/},
	abstract = {Head over to the Community Page for project tutorials contributed by OpenBCI Community members! Use the "tutorials" tag to filter.},
	language = {en},
	urldate = {2022-06-29},
	journal = {Community Page Projects},
	author = {OpenBCI},
}

@misc{openbci_openbci_nodate,
	title = {{OpenBCI} {\textbar} {Citations}},
	url = {https://openbci.com/citations},
	language = {en},
	urldate = {2022-06-29},
	journal = {OpenBCI Citations Page},
	author = {OpenBCI},
}

@misc{zhang_openbci_nodate,
	type = {Google {Docs}},
	title = {{OpenBCI} {Citations} {List}},
	url = {https://docs.google.com/spreadsheets/d/1WvolD2-QJ5aUJy5o0Dq5wdFQtLMkMtppZT8s_ihYyA4/edit?usp=embed_facebook},
	abstract = {Citations

Year,OpenBCI Product Used,Electrode / Other Products,Author(s),Title,URL,Journal/Conference,DOI,Language,Keyword(s),Notes
2022,Cyton Board,Headband Kit,Aloaye E. Itsueli; Jonathan D. N. Kamba; Jeremie O. K. Kamba; R. Alba-Flores,Drone Control Using Electroencephalogram (EEG) Signals,{\textless}a...},
	language = {en-GB},
	urldate = {2022-06-29},
	journal = {OpenBCI Citations List},
	author = {Zhang, Shirley},
}

@misc{be_superhvman_conor_2017,
	title = {Conor {Russomanno} {\textbar} {Open}-sourcing the brain},
	url = {https://www.youtube.com/watch?v=NK2ns4kPRcA},
	abstract = {In one part talk, one part demonstration, Conor Russomanno showcases the world's first open-source brain computer interface (BCI). The hardware technology stands at the forefront of the neuro-revolution, an era where we understand how the electrical signals of the brain work, use them to shape our brain health, and quite possibly control the technologies around us. 

---

Superhuman celebrates our next evolution, bringing you the latest science, technology and groundbreaking achievements in human self-enhancement.

WEBSITE: www.superhvman.com
FACEBOOK: www.facebook.com/besuperhvman
TWITTER: twitter.com/besuperhvman
INSTAGRAM: www.instagram.com/besuperhvman

---

Conor Russomanno’s future was established early on with a mixed background of engineering, art and design. While a Masters of Fine Arts student at Parsons School of Design, Conor discovered brain-computer interfacing and has since committed his life to the technology, making recording brain activity more cost-effective and accessible to everybody.},
	urldate = {2022-06-29},
	author = {{Be Superhvman}},
	month = mar,
	year = {2017},
}

@misc{muse_muse_nodate,
	title = {Muse - {Meditation} {Made} {Easy}},
	url = {https://choosemuse.com/de/},
	abstract = {Muse is an immersive meditation device that provides real-time feedback on your mental activity, heart rate, breathing, and body movements to help you build a consistent meditation practice.},
	language = {de-DE},
	urldate = {2022-06-29},
	journal = {Muse},
	author = {Muse},
}

@misc{louise_neurotechnology_2019,
	title = {Neurotechnology startup {NextMind} unveils world's first brain-sensing wearable that delivers real-time device control with just your thoughts},
	url = {https://techstartups.com/2019/11/22/neurotechnology-startup-nextmind-unveils-worlds-first-brain-sensing-wearable-delivers-real-time-device-control-just-thoughts/},
	abstract = {Nextmind, a Paris based neuro technology startup developing the next generation of brain computer interfaces,  today unveiled the world’s first brain-sensing wearable that delivers real-time device control using just a person’s thoughts at Slush 2019. This groundbreaking technology is a …},
	language = {en-US},
	urldate = {2022-06-29},
	journal = {Tech News {\textbar} Startups News},
	author = {Louise, Nickie},
	month = nov,
	year = {2019},
	note = {Section: Technology News},
}

@misc{openbci_ultracortex_nodate,
	type = {Documentation},
	title = {Ultracortex {Mark} {IV} {\textbar} {OpenBCI} {Documentation}},
	url = {https://openbci.github.io/AddOns/Headwear/MarkIV/},
	abstract = {Development Period: January 2016 Through the Present},
	language = {en},
	urldate = {2022-06-29},
	journal = {Ultracortex Mark IV {\textbar} OpenBCI Documentation},
	author = {OpenBCI},
}

@misc{neurotech_analytics_limited_global_nodate,
	title = {Global {Neurtech} {Ecosystem} {IT} {Platform}},
	url = {https://www.neurotech.com/it-platform},
	language = {en},
	urldate = {2022-06-28},
	journal = {Neurotech},
	author = {Neurotech Analytics Limited},
}

@misc{kernel_hello-humanitypdf_nodate,
	title = {hello-humanity.pdf},
	url = {https://www.kernel.com/hello-humanity.pdf},
	urldate = {2022-06-12},
	author = {Kernel},
}

@incollection{puderbaugh_neuroplasticity_2022,
	address = {Treasure Island (FL)},
	title = {Neuroplasticity},
	copyright = {Copyright © 2022, StatPearls Publishing LLC.},
	url = {http://www.ncbi.nlm.nih.gov/books/NBK557811/},
	abstract = {Neuroplasticity, also known as neural plasticity or brain plasticity, is a process that involves adaptive structural and functional changes to the brain. A good definition is “the ability of the nervous system to change its activity in response to intrinsic or extrinsic stimuli by reorganizing its structure, functions, or connections.”[1] Clinically, it is the process of brain changes after injury, such as a stroke or traumatic brain injury (TBI). These changes can either be beneficial (restoration of function after injury), neutral (no change), or negative (can have pathological consequences). Neuroplasticity can be broken down into two major mechanisms: Neuronal regeneration/collateral sprouting: This includes concepts such as synaptic plasticity and neurogenesis. Functional reorganization: This includes concepts such as equipotentiality, vicariation, and diaschisis. The first mention of the term plasticity in regards to the nervous system was by William James in 1890.[2] However, the term neural plasticity is credited to Jerzy Konorski in 1948[1] and was popularized by Donald Hebb in 1949.[3]},
	language = {eng},
	urldate = {2022-06-12},
	booktitle = {{StatPearls}},
	publisher = {StatPearls Publishing},
	author = {Puderbaugh, Matt and Emmady, Prabhu D.},
	year = {2022},
	pmid = {32491743},
}

@misc{noauthor_imaging_nodate,
	title = {Imaging study},
	url = {https://www.ukbiobank.ac.uk/explore-your-participation/contribute-further/imaging-study},
	urldate = {2022-06-12},
}

@article{callaway_can_2022,
	title = {Can brain scans reveal behaviour? {Bombshell} study says not yet},
	volume = {603},
	copyright = {2022 Nature},
	shorttitle = {Can brain scans reveal behaviour?},
	url = {https://www.nature.com/articles/d41586-022-00767-3},
	doi = {10.1038/d41586-022-00767-3},
	abstract = {Most studies linking features in brain imaging to traits such as cognitive abilities are too small to be reliable, argues a controversial analysis.},
	language = {en},
	number = {7903},
	urldate = {2022-06-12},
	journal = {Nature},
	author = {Callaway, Ewen},
	month = mar,
	year = {2022},
	note = {Bandiera\_abtest: a
Cg\_type: News
Number: 7903
Publisher: Nature Publishing Group
Subject\_term: Neuroscience, Brain},
	keywords = {Brain, Neuroscience},
	pages = {777--778},
}

@article{marek_reproducible_2022,
	title = {Reproducible brain-wide association studies require thousands of individuals},
	volume = {603},
	copyright = {2022 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-022-04492-9},
	doi = {10.1038/s41586-022-04492-9},
	abstract = {Magnetic resonance imaging (MRI) has transformed our understanding of the human brain through well-replicated mapping of abilities to specific structures (for example, lesion studies) and functions1–3 (for example, task functional MRI (fMRI)). Mental health research and care have yet to realize similar advances from MRI. A primary challenge has been replicating associations between inter-individual differences in brain structure or function and complex cognitive or mental health phenotypes (brain-wide association studies (BWAS)). Such BWAS have typically relied on sample sizes appropriate for classical brain mapping4 (the median neuroimaging study sample size is about 25), but potentially too small for capturing reproducible brain–behavioural phenotype associations5,6. Here we used three of the largest neuroimaging datasets currently available—with a total sample size of around 50,000 individuals—to quantify BWAS effect sizes and reproducibility as a function of sample size. BWAS associations were smaller than previously thought, resulting in statistically underpowered studies, inflated effect sizes and replication failures at typical sample sizes. As sample sizes grew into the thousands, replication rates began to improve and effect size inflation decreased. More robust BWAS effects were detected for functional MRI (versus structural), cognitive tests (versus mental health questionnaires) and multivariate methods (versus univariate). Smaller than expected brain–phenotype associations and variability across population subsamples can explain widespread BWAS replication failures. In contrast to non-BWAS approaches with larger effects (for example, lesions, interventions and within-person), BWAS reproducibility requires samples with thousands of individuals.},
	language = {en},
	number = {7902},
	urldate = {2022-06-12},
	journal = {Nature},
	author = {Marek, Scott and Tervo-Clemmens, Brenden and Calabro, Finnegan J. and Montez, David F. and Kay, Benjamin P. and Hatoum, Alexander S. and Donohue, Meghan Rose and Foran, William and Miller, Ryland L. and Hendrickson, Timothy J. and Malone, Stephen M. and Kandala, Sridhar and Feczko, Eric and Miranda-Dominguez, Oscar and Graham, Alice M. and Earl, Eric A. and Perrone, Anders J. and Cordova, Michaela and Doyle, Olivia and Moore, Lucille A. and Conan, Gregory M. and Uriarte, Johnny and Snider, Kathy and Lynch, Benjamin J. and Wilgenbusch, James C. and Pengo, Thomas and Tam, Angela and Chen, Jianzhong and Newbold, Dillan J. and Zheng, Annie and Seider, Nicole A. and Van, Andrew N. and Metoki, Athanasia and Chauvin, Roselyne J. and Laumann, Timothy O. and Greene, Deanna J. and Petersen, Steven E. and Garavan, Hugh and Thompson, Wesley K. and Nichols, Thomas E. and Yeo, B. T. Thomas and Barch, Deanna M. and Luna, Beatriz and Fair, Damien A. and Dosenbach, Nico U. F.},
	month = mar,
	year = {2022},
	note = {Number: 7902
Publisher: Nature Publishing Group},
	keywords = {Cognitive neuroscience, Psychology},
	pages = {654--660},
}

@misc{noauthor_action_2016,
	title = {Action potentials and synapses},
	url = {https://qbi.uq.edu.au/brain-basics/brain/brain-physiology/action-potentials-and-synapses},
	abstract = {Understand in detail the neuroscience behind action potentials and nerve cell synapses},
	language = {en},
	urldate = {2022-06-11},
	month = nov,
	year = {2016},
}

@techreport{hu_model_2021,
	title = {Model {Complexity} of {Deep} {Learning}: {A} {Survey}},
	shorttitle = {Model {Complexity} of {Deep} {Learning}},
	url = {http://arxiv.org/abs/2103.05127},
	abstract = {Model complexity is a fundamental problem in deep learning. In this paper we conduct a systematic overview of the latest studies on model complexity in deep learning. Model complexity of deep learning can be categorized into expressive capacity and effective model complexity. We review the existing studies on those two categories along four important factors, including model framework, model size, optimization process and data complexity. We also discuss the applications of deep learning model complexity including understanding model generalization, model optimization, and model selection and design. We conclude by proposing several interesting future directions.},
	number = {arXiv:2103.05127},
	urldate = {2022-05-29},
	institution = {arXiv},
	author = {Hu, Xia and Chu, Lingyang and Pei, Jian and Liu, Weiqing and Bian, Jiang},
	month = aug,
	year = {2021},
	doi = {10.48550/arXiv.2103.05127},
	note = {arXiv:2103.05127 [cs]
type: article},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{rashid_bilateral_2018,
	title = {Bilateral {Motor} {Cortex} {Control} for {Left} {Thumb} {Movement}: {An} {Incidental} {Finding} {Through} {Functional} {MRI} ({fMRI})},
	volume = {2018},
	copyright = {© BMJ Publishing Group Ltd (unless otherwise stated in the text of the article) 2018. All rights reserved. No commercial use is permitted unless otherwise expressly granted.},
	issn = {1757-790X},
	shorttitle = {Bilateral {Motor} {Cortex} {Control} for {Left} {Thumb} {Movement}},
	url = {https://casereports.bmj.com/content/2018/bcr-2017-221129},
	doi = {10.1136/bcr-2017-221129},
	abstract = {We report a case of a healthy, right-hand dominant young male who was a volunteer for a pilot run of a functional MRI (fMRI) study. The fMRI was performed with a 3.0 Tesla MRI scanner using a finger tapping task-based activity. The subjects were instructed to perform flexion of the right thumb and left thumb consecutively (activation task) and neuronal activation in bilateral primary motor cortex (PMC) were observed during each task. One particular subject demonstrated bilateral PMC activation during the left-thumb movement task, instead of the expected activation of the contralateral PMC alone.},
	language = {en},
	urldate = {2022-05-29},
	journal = {Case Reports},
	author = {Rashid, Aida and Suppiah, Subapriya and Hoo, Fan Kee and Masiran, Ruziana},
	month = jan,
	year = {2018},
	pmid = {29301796},
	note = {Publisher: BMJ Publishing Group
Section: Unexpected outcome (positive or negative) including adverse drug reactions},
	keywords = {disability, neuroimaging, radiology, rehabilitation medicine},
	pages = {bcr},
}

@book{luria_working_1976,
	address = {New York},
	edition = {Revised ed. edition},
	title = {The {Working} {Brain}: {An} {Introduction} {To} {Neuropsychology}},
	isbn = {978-0-465-09208-6},
	shorttitle = {The {Working} {Brain}},
	language = {English},
	publisher = {Basic Books},
	author = {Luria, Aleksandr R.},
	month = feb,
	year = {1976},
}

@inproceedings{demasi_theoretical_2010,
	title = {A {Theoretical} {Framework} to {Formalize} {AGI}-{Hard} {Problems}},
	isbn = {978-90-78677-36-9},
	url = {https://www.atlantis-press.com/proceedings/agi10/1912},
	doi = {10.2991/agi.2010.14},
	abstract = {The main goal of the Artificial General Intelligence field (AGI) to create human level intelligence is known as a very ambitious one. On the way to the field development there are many difficult problems to solve, like natural language translation, for example, which seem to share some 'hardness' properties. The terms 'AI-Complete' and 'Hard' by analogy...},
	language = {en},
	urldate = {2022-05-29},
	publisher = {Atlantis Press},
	author = {Demasi, Pedro and Szwarcfiter, Jayme L. and Cruz, Adriano J. O.},
	month = jun,
	year = {2010},
	note = {ISSN: 1951-6851},
	pages = {64--65},
}

@article{amit_asymmetrical_2017,
	title = {An asymmetrical relationship between verbal and visual thinking: {Converging} evidence from behavior and {fMRI}},
	volume = {152},
	issn = {1053-8119},
	shorttitle = {An asymmetrical relationship between verbal and visual thinking},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811917302379},
	doi = {10.1016/j.neuroimage.2017.03.029},
	abstract = {Humans rely on at least two modes of thought: verbal (inner speech) and visual (imagery). Are these modes independent, or does engaging in one entail engaging in the other? To address this question, we performed a behavioral and an fMRI study. In the behavioral experiment, participants received a prompt and were asked to either silently generate a sentence or create a visual image in their mind. They were then asked to judge the vividness of the resulting representation, and of the potentially accompanying representation in the other format. In the fMRI experiment, participants had to recall sentences or images (that they were familiarized with prior to the scanning session) given prompts, or read sentences and view images, in the control, perceptual, condition. An asymmetry was observed between inner speech and visual imagery. In particular, inner speech was engaged to a greater extent during verbal than visual thought, but visual imagery was engaged to a similar extent during both modes of thought. Thus, it appears that people generate more robust verbal representations during deliberate inner speech compared to when their intent is to visualize. However, they generate visual images regardless of whether their intent is to visualize or to think verbally. One possible interpretation of these results is that visual thinking is somehow primary, given the relatively late emergence of verbal abilities during human development and in the evolution of our species.},
	language = {en},
	urldate = {2022-05-29},
	journal = {NeuroImage},
	author = {Amit, Elinor and Hoeflin, Caitlyn and Hamzah, Nada and Fedorenko, Evelina},
	month = may,
	year = {2017},
	keywords = {Inner speech, Modes of thought, Visual imagery, fMRI},
	pages = {619--627},
}

@article{vidal_real-time_1977,
	title = {Real-time detection of brain events in {EEG}},
	doi = {10.1109/PROC.1977.10542},
	abstract = {It is shown here that, at least in some situations, it is possible to detect and classify individual evoked responses or "single epochs" with surprising reliability. Evoked responses or event related potentials in human EEG have been mostly studied with off-line analog recording and averaging. It is shown here that, at least in some situations, it is possible to detect and classify individual evoked responses or "single epochs" with surprising reliability. To do so, however, requited thinking a new not only the data processing but the whole experimental strategy. The classification is done in real-time by treating the experiments as a signal detection problem in which the computer, in the position of impartial observer, assigns classes to incoming epochs accogding to a predetermined decision rule. Since data collection and processing are interleaved, each classification outcome can be a factor in experiment control as well as in subject feedback. The discrimination performance, expressed in terms of mutual information, is shown to be both a practical index for procedure optimization and a concise and specific descriptor for the experiment results.},
	journal = {Proceedings of the IEEE},
	author = {Vidal, Jacques J.},
	year = {1977},
}

@inproceedings{dietrich_limitations_2010,
	title = {Limitations, possibilities and implications of {Brain}-{Computer} {Interfaces}},
	doi = {10.1109/HSI.2010.5514488},
	abstract = {EEG Systems and Brain-Computer Interfaces (BCIs) are terms that are commonly used and discussed in the field of neurological research. From a technological point of view, the components and techniques used to build technical devices for this purpose are also widely discussed. Undifferentiated use of the terms EEG Systems and BCIs in the same context provokes a discussion because they in fact refer to distinct and different concepts and should be treated accordingly. This assertion shall be discussed and established without going into more technical detail of the concrete components. We will discuss the associated problem of the vague definition of BCIs and depict the essential limitations when using skull potential signals to realize such devices. To demonstrate alternative ways of realizing man-machine interfaces, we will describe the most recent research results, based on the example of a complex arm prosthesis. With respect to the requirements for realizing such a complex prosthesis we will show the possibilities and limitations of accessing the human brain structures and finally propose clear conclusions regarding the specifications for Brain-Computer Interfaces and the corresponding long term research and development goals.},
	booktitle = {3rd {International} {Conference} on {Human} {System} {Interaction}},
	author = {Dietrich, Dietmar and Lang, Roland and Bruckner, Dietmar and Fodor, Georg and Müller, Brit},
	month = may,
	year = {2010},
	note = {ISSN: 2158-2254},
	keywords = {Antenna accessories, Biomedical signal processing, Brain computer interfaces, Brain-Computer Interface, Brain/ Mind Interfaces, Electroencephalography, Electromagnetic measurements, Human-Machine Interaction, Humans, Prosthetics, Psychology, Signal processing, Wireless sensor networks},
	pages = {722--726},
}

@inproceedings{minguillon_mobile_2017,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Mobile} {Brain}-{Computer} {Interface} for {Clinical} {Applications}: {From} the {Lab} to the {Ubiquity}},
	isbn = {978-3-319-59773-7},
	shorttitle = {A {Mobile} {Brain}-{Computer} {Interface} for {Clinical} {Applications}},
	doi = {10.1007/978-3-319-59773-7_8},
	abstract = {Technological advances during the last years have contributed to the development of wireless and low-cost electroencephalography (EEG) acquisition systems and mobile brain-computer interface (mBCI) applications. The most popular applications are general-purpose (e.g., games, sports, daily-life, etc.). However, clinical usefulness of mBCIs is still an open question. In this paper we present a low-cost mobile BCI application and demonstrate its potential utility in clinical practice. In particular, we conducted a study in which visual evoked potentials (VEP) of two subjects were analyzed using our mBCI application, under different conditions: inside a laboratory, walking and traveling in a car. The results show that the features of our system (level of synchronization, robustness and signal quality) are acceptable for the demanding standard required for the electrophysiological evaluation of vision. In addition, the mobile recording and cloud computing of VEPs offers a number of advantages over traditional in-lab systems. The presented mobile application could be used for visual impairment screening, for ubiquitous, massive and low-cost evaluation of vision, and as ambulatory diagnostic tool in rural or undeveloped areas.},
	language = {en},
	booktitle = {Biomedical {Applications} {Based} on {Natural} and {Artificial} {Computing}},
	publisher = {Springer International Publishing},
	author = {Minguillon, Jesus and Lopez-Gordo, Miguel Angel and Morillas, Christian and Pelayo, Francisco},
	editor = {Ferrández Vicente, José Manuel and Álvarez-Sánchez, José Ramón and de la Paz López, Félix and Toledo Moreo, Javier and Adeli, Hojjat},
	year = {2017},
	keywords = {Clinical, Cloud-computing, EEG, Mobile brain-computer interface, Ubiquity, VEP, mBCI, mHealth},
	pages = {68--76},
}

@misc{campbell_amputee_2014,
	title = {Amputee becomes first to simultaneously use two {APL} {Modular} {Prosthetic} {Limbs}},
	url = {https://hub.jhu.edu/2014/12/17/amputee-makes-history/},
	abstract = {Man who lost both arms 40 years ago operates APL-designed system simply by thinking about moving his limbs},
	language = {en},
	urldate = {2022-05-08},
	journal = {The Hub},
	author = {Campbell, Paulette},
	month = dec,
	year = {2014},
}

@article{belkacem_brain_2020,
	title = {Brain {Computer} {Interfaces} for {Improving} the {Quality} of {Life} of {Older} {Adults} and {Elderly} {Patients}},
	volume = {14},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/article/10.3389/fnins.2020.00692},
	abstract = {All people experience aging, and the related physical and health changes, including changes in memory and brain function. These changes may become debilitating leading to an increase in dependence as people get older. Many external aids and tools have been developed to allow older adults and elderly patients to continue to live normal and comfortable lives. This mini-review describes some of the recent studies on cognitive decline and motor control impairment with the goal of advancing non-invasive brain computer interface (BCI) technologies to improve health and wellness of older adults and elderly patients. First, we describe the state of the art in cognitive prosthetics for psychiatric diseases. Then, we describe the state of the art of possible assistive BCI applications for controlling an exoskeleton, a wheelchair and smart home for elderly people with motor control impairments. The basic age-related brain and body changes, the effects of age on cognitive and motor abilities, and several BCI paradigms with typical tasks and outcomes are thoroughly described. We also discuss likely future trends and technologies to assist healthy older adults and elderly patients using innovative BCI applications with minimal technical oversight.},
	urldate = {2022-05-08},
	journal = {Frontiers in Neuroscience},
	author = {Belkacem, Abdelkader Nasreddine and Jamil, Nuraini and Palmer, Jason A. and Ouhbi, Sofia and Chen, Chao},
	year = {2020},
}

@article{chaudhary_spelling_2022,
	title = {Spelling interface using intracortical signals in a completely locked-in patient enabled via auditory neurofeedback training},
	volume = {13},
	copyright = {2022 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-022-28859-8},
	doi = {10.1038/s41467-022-28859-8},
	abstract = {Patients with amyotrophic lateral sclerosis (ALS) can lose all muscle-based routes of communication as motor neuron degeneration progresses, and ultimately, they may be left without any means of communication. While others have evaluated communication in people with remaining muscle control, to the best of our knowledge, it is not known whether neural-based communication remains possible in a completely locked-in state. Here, we implanted two 64 microelectrode arrays in the supplementary and primary motor cortex of a patient in a completely locked-in state with ALS. The patient modulated neural firing rates based on auditory feedback and he used this strategy to select letters one at a time to form words and phrases to communicate his needs and experiences. This case study provides evidence that brain-based volitional communication is possible even in a completely locked-in state.},
	language = {en},
	number = {1},
	urldate = {2022-05-08},
	journal = {Nature Communications},
	author = {Chaudhary, Ujwal and Vlachos, Ioannis and Zimmermann, Jonas B. and Espinosa, Arnau and Tonin, Alessandro and Jaramillo-Gonzalez, Andres and Khalili-Ardali, Majid and Topka, Helge and Lehmberg, Jens and Friehs, Gerhard M. and Woodtli, Alain and Donoghue, John P. and Birbaumer, Niels},
	month = mar,
	year = {2022},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Amyotrophic lateral sclerosis, Quality of life, Single-channel recording},
	pages = {1236},
}

@misc{wyss_center_neurokey_nodate,
	title = {{NeuroKey}™},
	url = {https://wysscenter.ch/advances/neurokey},
	abstract = {Real-time neural signal processing platform},
	language = {en},
	urldate = {2022-04-03},
	journal = {Wyss Center},
	author = {Wyss Center},
}

@article{murphy_electroencephalogram-based_2017,
	title = {Electroencephalogram-{Based} {Brain}-{Computer} {Interface} and {Lower}-{Limb} {Prosthesis} {Control}: {A} {Case} {Study}},
	volume = {8},
	issn = {1664-2295},
	shorttitle = {Electroencephalogram-{Based} {Brain}-{Computer} {Interface} and {Lower}-{Limb} {Prosthesis} {Control}},
	doi = {10.3389/fneur.2017.00696},
	abstract = {OBJECTIVE: The purpose of this study was to establish the feasibility of manipulating a prosthetic knee directly by using a brain-computer interface (BCI) system in a transfemoral amputee. Although the other forms of control could be more reliable and quick (e.g., electromyography control), the electroencephalography (EEG)-based BCI may provide amputees an alternative way to control a prosthesis directly from brain.
METHODS: A transfemoral amputee subject was trained to activate a knee-unlocking switch through motor imagery of the movement of his lower extremity. Surface scalp electrodes transmitted brain wave data to a software program that was keyed to activate the switch when the event-related desynchronization in EEG reached a certain threshold. After achieving more than 90\% reliability for switch activation by EEG rhythm-feedback training, the subject then progressed to activating the knee-unlocking switch on a prosthesis that turned on a motor and unlocked a prosthetic knee. The project took place in the prosthetic department of a Veterans Administration medical center. The subject walked back and forth in the parallel bars and unlocked the knee for swing phase and for sitting down. The success of knee unlocking through this system was measured. Additionally, the subject filled out a questionnaire on his experiences.
RESULTS: The success of unlocking the prosthetic knee mechanism ranged from 50 to 100\% in eight test segments.
CONCLUSION: The performance of the subject supports the feasibility for BCI control of a lower extremity prosthesis using surface scalp EEG electrodes. Investigating direct brain control in different types of patients is important to promote real-world BCI applications.},
	language = {eng},
	journal = {Frontiers in Neurology},
	author = {Murphy, Douglas P. and Bai, Ou and Gorgey, Ashraf S. and Fox, John and Lovegreen, William T. and Burkhardt, Brian W. and Atri, Roozbeh and Marquez, Juan S. and Li, Qi and Fei, Ding-Yu},
	year = {2017},
	pmid = {29326653},
	pmcid = {PMC5736540},
	keywords = {brain–computer interfaces, control, electroencephalography, lower limb, prosthesis, rhythm modulation},
	pages = {696},
}

@article{alimardani_passive_2020,
	title = {Passive {Brain}-{Computer} {Interfaces} for {Enhanced} {Human}-{Robot} {Interaction}},
	volume = {7},
	issn = {2296-9144},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7805996/},
	doi = {10.3389/frobt.2020.00125},
	abstract = {Brain-computer interfaces (BCIs) have long been seen as control interfaces that translate changes in brain activity, produced either by means of a volitional modulation or in response to an external stimulation. However, recent trends in the BCI and neurofeedback research highlight passive monitoring of a user's brain activity in order to estimate cognitive load, attention level, perceived errors and emotions. Extraction of such higher order information from brain signals is seen as a gateway for facilitation of interaction between humans and intelligent systems. Particularly in the field of robotics, passive BCIs provide a promising channel for prediction of user's cognitive and affective state for development of a user-adaptive interaction. In this paper, we first illustrate the state of the art in passive BCI technology and then provide examples of BCI employment in human-robot interaction (HRI). We finally discuss the prospects and challenges in integration of passive BCIs in socially demanding HRI settings. This work intends to inform HRI community of the opportunities offered by passive BCI systems for enhancement of human-robot interaction while recognizing potential pitfalls.},
	urldate = {2022-05-08},
	journal = {Frontiers in Robotics and AI},
	author = {Alimardani, Maryam and Hiraki, Kazuo},
	month = oct,
	year = {2020},
	pmid = {33501291},
	pmcid = {PMC7805996},
	pages = {125},
}

@misc{braingate_publications_nodate,
	title = {Publications {Timeline}},
	url = {https://www.braingate.org/publications-timeline},
	abstract = {BrainGate Publication Timelines AllSelected Achievements Neuroscience Neural EngineeringCommunicationMovement RestorationSpeech RestorationNeurotherapeutics},
	language = {en-US},
	urldate = {2022-05-08},
	journal = {BrainGate},
	author = {BrainGate},
}

@inproceedings{stegman_webbci_2018,
	title = {Webbci: {An} electroencephalography toolkit built on modern web technologies},
	shorttitle = {Webbci},
	booktitle = {International {Conference} on {Augmented} {Cognition}},
	publisher = {Springer},
	author = {Stegman, Pierce and Crawford, Chris and Gray, Jeff},
	month = jun,
	year = {2018},
	pages = {212--221},
}

@misc{amazon_web_services_inc_announcing_2006,
	title = {Announcing {Amazon} {Elastic} {Compute} {Cloud} ({Amazon} {EC2}) - beta},
	url = {https://aws.amazon.com/about-aws/whats-new/2006/08/24/announcing-amazon-elastic-compute-cloud-amazon-ec2---beta/},
	language = {en-US},
	urldate = {2022-05-08},
	journal = {Amazon Web Services, Inc.},
	author = {Amazon Web Services, Inc.},
	month = aug,
	year = {2006},
}

@misc{fernick_whitepaper_nodate,
	title = {Whitepaper: {Internet} of {Thinks}: {Securing} the {Brain} {Computer} {Interface} ({BCI})},
	shorttitle = {Whitepaper},
	url = {https://www.jdsupra.com/legalnews/whitepaper-internet-of-thinks-securing-1967522/},
	abstract = {This whitepaper attempts to provide a high-level overview of technological development in Brain Computer Interfaces (BCIs), and to anticipate the...},
	language = {en},
	urldate = {2022-04-02},
	journal = {JD Supra},
	author = {Fernick, Jennifer and Lewis, Matt},
}

@misc{higgins_intersection_2021,
	title = {The intersection of {UX} and brain-computer interfaces {\textbar} {Krystal} {Higgins}},
	url = {https://www.kryshiggins.com/ux-bcis/},
	language = {en-US},
	urldate = {2022-04-02},
	journal = {User experience \& onboarding},
	author = {Higgins, Krystal},
	month = jun,
	year = {2021},
}

@misc{russell_progressive_2015,
	title = {Progressive {Web} {Apps}: {Escaping} {Tabs} {Without} {Losing} {Our} {Soul}},
	shorttitle = {Progressive {Web} {Apps}},
	url = {https://infrequently.org/2015/06/progressive-apps-escaping-tabs-without-losing-our-soul/},
	abstract = {Progressive Web Apps are aren't packaged and deployed through stores, they're just websites that took all the right vitamins.},
	language = {en},
	urldate = {2022-03-27},
	journal = {Infrequently Noted},
	author = {Russell, Alex},
	month = jun,
	year = {2015},
}

@misc{gonfalonieri_deep_2019,
	title = {Deep {Learning} {Algorithms} and {Brain}-{Computer} {Interfaces}},
	url = {https://towardsdatascience.com/deep-learning-algorithms-and-brain-computer-interfaces-7608d0a6f01},
	abstract = {As part of a research team, I wanted to explain how Deep learning (DL) has lifted the performance of brain-computer interface systems…},
	language = {en},
	urldate = {2022-05-08},
	journal = {Medium},
	author = {Gonfalonieri, Alexandre},
	month = nov,
	year = {2019},
}

@inproceedings{qian_cloud_2009,
	title = {Cloud {Computing}: {An} {Overview}},
	volume = {5931},
	isbn = {978-3-642-10664-4},
	shorttitle = {Cloud {Computing}},
	doi = {10.1007/978-3-642-10665-1_63},
	abstract = {In order to support the maximum number of user and elastic service with the minimum resource, the Internet service provider invented the cloud computing. within a few years, emerging cloud computing has became the hottest technology. From the publication of core papers by Google since 2003 to the commercialization of Amazon EC2 in 2006, and to the service offering of AT\&T Synaptic Hosting, the cloud computing has been evolved from internal IT system to public service, from cost-saving tools to revenue generator, and from ISP to telecom. This paper introduces the concept, history, pros and cons of cloud computing as well as the value chain and standardization effort.},
	author = {Qian, Ling and Luo, Zhiguo and Du, Yujian and Guo, Leitao},
	month = jan,
	year = {2009},
	pages = {626--631},
}

@article{zander_combining_2010,
	title = {Combining {Eye} {Gaze} {Input} {With} a {Brain}–{Computer} {Interface} for {Touchless} {Human}–{Computer} {Interaction}},
	volume = {27},
	issn = {1044-7318},
	url = {https://doi.org/10.1080/10447318.2011.535752},
	doi = {10.1080/10447318.2011.535752},
	abstract = {A Brain–Computer Interface (BCI) provides a new communication channel for severely disabled people who have completely or partially lost control over muscular activity. It is questionable whether a BCI is the best choice for controlling a device if partial muscular activity still is available. For example, gaze-based interfaces can be utilized for people who are still able to control their eye movements. Such interfaces suffer from the lack of a natural degree of freedom for the selection command (e.g., a mouse click). One workaround for this problem is based on so-called dwell times, which easily leads to errors if the users do not pay close attention to where they are looking. We developed a multimodal interface combining eye movements and a BCI to a hybrid BCI, resulting in a robust and intuitive device for touchless interaction. This system especially is capable of dealing with different stimulus complexities.},
	number = {1},
	urldate = {2022-05-02},
	journal = {International Journal of Human–Computer Interaction},
	author = {Zander, Thorsten   O. and Gaertner, Matti and Kothe, Christian and Vilimek, Roman},
	month = dec,
	year = {2010},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10447318.2011.535752},
	pages = {38--51},
}

@article{putze_editorial_2020,
	title = {Editorial: {Brain}-{Computer} {Interfaces} and {Augmented}/{Virtual} {Reality}},
	volume = {14},
	issn = {1662-5161},
	shorttitle = {Editorial},
	url = {https://www.frontiersin.org/article/10.3389/fnhum.2020.00144},
	urldate = {2022-04-24},
	journal = {Frontiers in Human Neuroscience},
	author = {Putze, Felix and Vourvopoulos, Athanasios and Lécuyer, Anatole and Krusienski, Dean and Bermúdez i Badia, Sergi and Mullen, Timothy and Herff, Christian},
	year = {2020},
}

@article{saha_progress_2021,
	title = {Progress in {Brain} {Computer} {Interface}: {Challenges} and {Opportunities}},
	volume = {15},
	issn = {1662-5137},
	shorttitle = {Progress in {Brain} {Computer} {Interface}},
	url = {https://www.frontiersin.org/article/10.3389/fnsys.2021.578875},
	abstract = {Brain computer interfaces (BCI) provide a direct communication link between the brain and a computer or other external devices. They offer an extended degree of freedom either by strengthening or by substituting human peripheral working capacity and have potential applications in various fields such as rehabilitation, affective computing, robotics, gaming, and neuroscience. Significant research efforts on a global scale have delivered common platforms for technology standardization and help tackle highly complex and non-linear brain dynamics and related feature extraction and classification challenges. Time-variant psycho-neurophysiological fluctuations and their impact on brain signals impose another challenge for BCI researchers to transform the technology from laboratory experiments to plug-and-play daily life. This review summarizes state-of-the-art progress in the BCI field over the last decades and highlights critical challenges.},
	urldate = {2022-04-24},
	journal = {Frontiers in Systems Neuroscience},
	author = {Saha, Simanto and Mamun, Khondaker A. and Ahmed, Khawza and Mostafa, Raqibul and Naik, Ganesh R. and Darvishi, Sam and Khandoker, Ahsan H. and Baumert, Mathias},
	year = {2021},
}

@inproceedings{holloman_leveraging_2019,
	title = {Leveraging neurophysiological information to augment interpretation of responses to vulnerable robot behaviors},
	booktitle = {2019 14th {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction} ({HRI})},
	publisher = {IEEE},
	author = {Holloman, Amanda and Egbert, William and Stegman, Pierce and Cioli, Nicholas and Crawford, Chris S.},
	year = {2019},
	pages = {566--567},
}

@article{stegman_braincomputer_2020,
	title = {Brain–computer interface software: {A} review and discussion},
	volume = {50},
	shorttitle = {Brain–computer interface software},
	number = {2},
	journal = {IEEE Transactions on Human-Machine Systems},
	author = {Stegman, Pierce and Crawford, Chris S. and Andujar, Marvin and Nijholt, Anton and Gilbert, Juan E.},
	year = {2020},
	note = {Publisher: IEEE},
	pages = {101--115},
}

@article{shih_brain-computer_2012,
	title = {Brain-{Computer} {Interfaces} in {Medicine}},
	volume = {87},
	issn = {0025-6196},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3497935/},
	doi = {10.1016/j.mayocp.2011.12.008},
	abstract = {Brain-computer interfaces (BCIs) acquire brain signals, analyze them, and translate them into commands that are relayed to output devices that carry out desired actions. BCIs do not use normal neuromuscular output pathways. The main goal of BCI is to replace or restore useful function to people disabled by neuromuscular disorders such as amyotrophic lateral sclerosis, cerebral palsy, stroke, or spinal cord injury. From initial demonstrations of electroencephalography-based spelling and single-neuron-based device control, researchers have gone on to use electroencephalographic, intracortical, electrocorticographic, and other brain signals for increasingly complex control of cursors, robotic arms, prostheses, wheelchairs, and other devices. Brain-computer interfaces may also prove useful for rehabilitation after stroke and for other disorders. In the future, they might augment the performance of surgeons or other medical professionals. Brain-computer interface technology is the focus of a rapidly growing research and development enterprise that is greatly exciting scientists, engineers, clinicians, and the public in general. Its future achievements will depend on advances in 3 crucial areas. Brain-computer interfaces need signal-acquisition hardware that is convenient, portable, safe, and able to function in all environments. Brain-computer interface systems need to be validated in long-term studies of real-world use by people with severe disabilities, and effective and viable models for their widespread dissemination must be implemented. Finally, the day-to-day and moment-to-moment reliability of BCI performance must be improved so that it approaches the reliability of natural muscle-based function.},
	number = {3},
	urldate = {2022-03-31},
	journal = {Mayo Clinic Proceedings},
	author = {Shih, Jerry J. and Krusienski, Dean J. and Wolpaw, Jonathan R.},
	month = mar,
	year = {2012},
	pmid = {22325364},
	pmcid = {PMC3497935},
	pages = {268--279},
}

@incollection{angelica_cognitive_2021,
	address = {Cham},
	series = {Contemporary {Clinical} {Neuroscience}},
	title = {Cognitive {Augmentation} {Via} a {Brain}/{Cloud} {Interface}},
	isbn = {978-3-030-54564-2},
	url = {https://doi.org/10.1007/978-3-030-54564-2_17},
	abstract = {A core element of modern human society is its capacity to rapidly and efficiently communicate through multiple digital formats. Today, we are witnessing exponential progress in our ability to communicate essentially instantaneously on a global scale. When we extrapolate along this trajectory, particularly in view of the equally exponential advances being made in the domains of nanotechnology, nanomedicine, and AI, it appears logical that the communication platforms we use today in the form of smart phones, etc. will continue in their sophistication and miniaturization to the point where they cease to be external devices and become intimately and seamlessly integrated with our biologies. Specifically, the future discipline of neuralnanorobotics (via a set of hypothetical, for now, nanorobotic species designated as endoneurorobots, gliabots, and synapobots) might facilitate a direct and seamless interface between the human neocortex and the cloud/edge, referred to here as a Brain/Cloud Interface (B/CI). This new paradigm may enable us to access the full breadth of human knowledge and engage in fully immersive entertainment and with high-resolution fully sensorial avatars, with the potential capacity to literally experience portions of other individual lives through “transparent shadowing” (TS) applications. Further, at the societal level, B/CIs may assist in ameliorating the loneliness epidemic (as virtual digital presences/experiences will be essentially indistinguishable from reality) and facilitate the propagation of human empathy worldwide. This may result in reduction of potential conflicts and enhanced cooperation. This chapter will explore these paradigm-shifting possibilities for cognitive augmentation toward envisioning what may be possible within the next few decades.},
	language = {en},
	urldate = {2021-09-23},
	booktitle = {Modern {Approaches} to {Augmentation} of {Brain} {Function}},
	publisher = {Springer International Publishing},
	author = {Angelica, A. and Opris, I. and Lebedev, Mikhail A. and Boehm, F. J.},
	editor = {Opris, Ioan and A. Lebedev, Mikhail and F. Casanova, Manuel},
	year = {2021},
	doi = {10.1007/978-3-030-54564-2_17},
	keywords = {Brain-computer interface, Brain-machine interface, Brain-to-brain interface, Brain/cloud interface, Medical nanorobots, Nanomedicine, Nanorobots, Nanotechnology, Neuralnanorobotics, Neuralnanorobots, Transparent shadowing},
	pages = {357--386},
}

@article{martins_human_2019,
	title = {Human {Brain}/{Cloud} {Interface}},
	volume = {13},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/article/10.3389/fnins.2019.00112},
	doi = {10.3389/fnins.2019.00112},
	abstract = {The Internet comprises a decentralized global system that serves humanity’s collective effort to generate, process, and store data, most of which is handled by the rapidly expanding cloud. A stable, secure, real-time system may allow for interfacing the cloud with the human brain. One promising strategy for enabling such a system, denoted here as a “human brain/cloud interface” (“B/CI”), would be based on technologies referred to here as “neuralnanorobotics.” Future neuralnanorobotics technologies are anticipated to facilitate accurate diagnoses and eventual cures for the ∼400 conditions that affect the human brain. Neuralnanorobotics may also enable a B/CI with controlled connectivity between neural activity and external data storage and processing, via the direct monitoring of the brain’s ∼86 × 109 neurons and ∼2 × 1014 synapses. Subsequent to navigating the human vasculature, three species of neuralnanorobots (endoneurobots, gliabots, and synaptobots) could traverse the blood–brain barrier (BBB), enter the brain parenchyma, ingress into individual human brain cells, and autoposition themselves at the axon initial segments of neurons (endoneurobots), within glial cells (gliabots), and in intimate proximity to synapses (synaptobots). They would then wirelessly transmit up to ∼6 × 1016 bits per second of synaptically processed and encoded human–brain electrical information via auxiliary nanorobotic fiber optics (30 cm3) with the capacity to handle up to 1018 bits/sec and provide rapid data transfer to a cloud based supercomputer for real-time brain-state monitoring and data extraction. A neuralnanorobotically enabled human B/CI might serve as a personalized conduit, allowing persons to obtain direct, instantaneous access to virtually any facet of cumulative human knowledge. Other anticipated applications include myriad opportunities to improve education, intelligence, entertainment, traveling, and other interactive experiences. A specialized application might be the capacity to engage in fully immersive experiential/sensory experiences, including what is referred to here as “transparent shadowing” (TS). Through TS, individuals might experience episodic segments of the lives of other willing participants (locally or remote) to, hopefully, encourage and inspire improved understanding and tolerance among all members of the human family.},
	urldate = {2021-09-23},
	journal = {Frontiers in Neuroscience},
	author = {Martins, Nuno R. B. and Angelica, Amara and Chakravarthy, Krishnan and Svidinenko, Yuriy and Boehm, Frank J. and Opris, Ioan and Lebedev, Mikhail A. and Swan, Melanie and Garan, Steven A. and Rosenfeld, Jeffrey V. and Hogg, Tad and Freitas, Robert A.},
	year = {2019},
	pages = {112},
}

@book{nhemachena_hakuna_2021,
	title = {Hakuna {Mhou} {Inokumira} {Mhuru} {Isiri} {Yayo}: {Examining} the {Interface} {Between} the {African} {Body} and {Twenty}-{First} {Century} {Emergent} {Disruptive} {Technologies} (final version published by the {Journal} of {Black} {Studies}, {June} 2021)},
	shorttitle = {Hakuna {Mhou} {Inokumira} {Mhuru} {Isiri} {Yayo}},
	abstract = {Colonially depicted as a region distinctive for fables and fabrications, Africa has ever since not been allowed to reclaim anything original. Dispossessed of their original wealth, Africans have been forced to live in fabled and fabricated houses, eating fabled and fabricated food-closer to animals. Similarly, dispossessed of their original human identities, Africans have been forced to adopt fabricated identities. With the twenty-first century not promising any return to original African human identities, Africans are set to be further nanotechnologically (using tiny nanoparticles) fabricated into cyborgs that speak to ongoing posthumanist and transhumanist experiments with emergent disruptive technologies. Inhabiting not only fabricated houses but also increasingly inhabiting nanotechnologically fabled and fabricated bodies, Africans should learn to, in terms of the Shona (a people of Zimbabwe) proverb, hakuna mhou inokumira mhuru isiri yayo (no cow lows for a calf that is not its own), repossess original mastery over their own lives.},
	author = {Nhemachena, Artwell},
	month = jun,
	year = {2021},
}
