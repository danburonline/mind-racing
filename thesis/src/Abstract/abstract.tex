\begin{abstract}

    Different HCI possibilities in VR applications: 6 degrees of freedom, controllers, hand tracking, treadmill, joysticks, etc. The goal of VR is full immersion, which means that human sensory input and output must be as natural as possible, e.g. high-resolution screens, spatial high definition audio, etc.

    Some interaction still relies on intermediaries such as pressing buttons on the controller or a joystick etc. Some are useful, but others are relics of today's computing: mice with pointers, keyboards, etc. They are intermediaries because technology in the 1970s was not yet ready to develop, for example, reliable multi-touch screens for the first wave of personal computers. The same thing is already happening in VR with, e.g. the hand controllers, as hand tracking was still a long way from becoming trustworthy. 

    But there are still interaction possibilities where the use of, e.g. our hands becomes very limited or uncomfortable, e.g. moving distant objects in a virtual 3D space, so it makes sense to use, e.g. a joystick. As with sensory information to achieve full-immersion in VR, there are countless opportunities and possibilities to achieve it.

    With my work, I use a proprietary in-ear EEG sensor to extend the interaction possibilities with the help of the brain and facial artefacts like eye movement etc., to make the experience in the virtual world more natural in the meaning of using sensory output from our body and brain to interact with a virtual world.
    
    There are several possibilities to use an in-ear located EEG sensors, e.g. eye movement, chewing, speaking, blinking, brain waves etc. More draft information coming soon.

\end{abstract}