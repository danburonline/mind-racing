\chapter{Flaws and bugs previous system}
\label{appendix2-flaws-and-bugs-previous-system}

This appendix lists the flaws and bugs discovered during the author’s work on the original IDUN Technologies PoC software system.

\begin{itemize}
  \item AWS Amplify is great for frontend developers who want to build simple backends with CRUD\footnote{CRUD is an acronym describing general operations of a backend system: create, read, update and delete.} operations, but it is not intended for anything custom-made, such as the streaming-focused aspect of EEG data. Therefore, AWS Amplify must be abandoned as soon as possible, or the project will be built with the wrong tools and foundations.
  \item The network bridge was a Raspberry Pi 4 Model B running Python code which, after some analysis, turned out to be the primary source of most of the bugs due to limits in computational power and ARM-based CPU architecture.
  \item The cloud’s heartbeat functionality was missing, which meant that the cloud knew nothing about the hardware devices, and simply assumed that data would flow in as soon as the start command was sent to the device, creating a ‘happy path’ scenario.
  \item The cloud infrastructure was automatically provisioned by AWS Amplify, which uses AWS CloudFormation in its core. CloudFormation is an infrastructure as code (IaC) tool, that runs inside AWS CodePipeline, AWS’s continuous integration service. This tool stack made everything coupled to specific AWS services where the technical decision to use them was not made based on reasoning but was based on Amplify’s creators to utilise them.
  \item All software in the cloud was built using the AWS Console (the AWS GUI). Therefore, no current state in the form of IaC reflected the current infrastructure, which made it difficult to reproduce the cloud in different environments, for example, such as preventing a blast radius if something went wrong.
  \item The data was streamed via the messaging and queuing middleware telemetry transport (MQTT) protocol developed by IBM in the late 1990s ]\citep{yuan_getting_2017}. MQTT is a publish-and-subscribe protocol commonly used for IoT devices that regularly send telemetry data. The purpose of MQTT was not to send high-frequency EEG data in real-time but rather to minimise network bandwidth \citep{mqtt_use_nodate}. Therefore, there was also a need to rethink this technological decision based on the nature of IDUN’s EEG sensor, which records EEG data at 250 Hz (250 samples per second).
  \item The SPA was a thick client, meaning that it ran a lot of business logic, such as filtering raw data for real-time visualisation. This was another technological misstep, as the client-side JavaScript ecosystem is far inferior to the Python ecosystem that could run in the backend to handle such tasks. If possible, shipping business logic that could hold intellectual property to clients should be avoided, if possible, especially with a commercial product.
  \item The SPA was not connected to a single endpoint on the backend and used the MQTT stream and the non-real-time aspects of the app (e.g. login or list of recorded EEG data) via different sources. For example, the MQTT stream was subscribed directly from the device itself and did not run through AWS Amplify’s API, which made it cumbersome to couple the systems into a coherent and robust API.
  \item The state of the entire system was difficult to handle due to the decoupled logic from the MQTT stream and Amplify’s API. Combined with the lack of a hardware heartbeat, it was tedious to figure out what the user was doing and what was being sent. As an interim solution, AWS ElastiCache—a provisioned service for in-memory databases such as Redis—was set up. Unfortunately, the application state was now both handled in the SPA and simultaneously on ElastiCache, which led to new problems such as sending EEG data to the void if the user closed the browser during a data stream.
\end{itemize}
