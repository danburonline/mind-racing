\chapter{Implementation}
\graphicspath{{Chapter4/Figs/}{Chapter4/Figs/}}

The implementation details of creating the software components for the NIP of IDUN are covered in this chapter, along with key events in the empirical software engineering process like the recognition of novelty and the requirement for a N/CI definition.

\section{Timeline}
\label{chapter4-timeline}

Procedures enlisted in the project stages presented in \autoref{chapter3-project-stages}, are a good guide for project implementation, but in the end, such plans run in unexpected ways. As a result, researching and implementing a non-trivial system such as a N/CI requires a high level of agility.

The effective timeline at the time of writing is shown in \autoref{fig:implementation-timeline}. It includes the previously mentioned project stages but is differently structured as initially described. \autoref{tab:special-project-stages} explains why some project stages were completed differently than initially planned.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\linewidth]{implementation-timeline.png}
  \caption{Effective timeline of the last ten sprints with project stages in white and specifically planned stages outlined in grey.}
  \label{fig:implementation-timeline}
\end{figure}

\begin{table}[ht]
  \centering
  \resizebox{\textwidth}{!}{%
    \begin{tabular}{
        >{\columncolor[HTML]{FFFFFF}}l l}
      \cellcolor[HTML]{000000}{\color[HTML]{FFFFFF} Special stage}                                                                               &
      \cellcolor[HTML]{000000}{\color[HTML]{FFFFFF} Description}                                                                                                                                                                                                                                                                                                                                                                                \\ \hline
      \multicolumn{1}{|l|}{\cellcolor[HTML]{FFFFFF}\textbf{\begin{tabular}[c]{@{}l@{}}[1] 3.2 Expert\\ interviews\end{tabular}}}                 &
      \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}The author was able to use the first expert discussions in advance thanks to the help of one\\ of the sales staff's networks. The experts were Nuvibit's experienced enterprise cloud and\\ solution architects. The first topics were strictly technical in nature, focusing on medium-\\ term technological decisions in the context of the company and the timetable.\end{tabular}}     \\ \hline
      \multicolumn{1}{|l|}{\cellcolor[HTML]{FFFFFF}\textbf{\begin{tabular}[c]{@{}l@{}}[2] 4. Start\\ bootstrapping\end{tabular}}}                &
      \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}This special stage describes the phase in which the author established more organisational\\ structures, such as a professional Scrum or GitHub setup. Furthermore, the time was used\\ to create a more professional AWS organisational setup with various organisational units,\\ as described in the AWS Best Practice Guide \citep{blackham_best_2020}.\end{tabular}}                  \\ \hline
      \multicolumn{1}{|l|}{\cellcolor[HTML]{FFFFFF}\textbf{\begin{tabular}[c]{@{}l@{}}[3] 4. Start\\ bootstrapping\end{tabular}}}                &
      \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}Since the creation of two different Python SDKs (as discussed later in this chapter), more\\ bootstrapping tasks were due at the very end of the given time frame, mostly including\\ the setup of a private PyPi installable Python package and SDK-specific quality\\ assurance pipelines and automations.\end{tabular}}                                                                 \\ \hline
      \multicolumn{1}{|l|}{\cellcolor[HTML]{FFFFFF}\textbf{\begin{tabular}[c]{@{}l@{}}[4] 5. Iterative and\\ agile implementation\end{tabular}}} &
      \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}Iterative and agile implementation began as soon as needed, without waiting for the design\\ process to be completed (i.e. avoiding a waterfall process). Prior to gaining insights from the \\ design process, time was spent on everything else, such as evaluating technologies, further\\ bootstrapping, first example codebases, or maintaining the old codebase a bit.\end{tabular}} \\ \hline
    \end{tabular}%
  }
  \vspace{10pt}
  \caption{Special project stages in the effective schedule as shown in \autoref{fig:implementation-timeline} and their explanation of why they took place there.}
  \vspace{-5pt}
  \label{tab:special-project-stages}
\end{table}

Several key events occurred during the implementation that shaped the future course of the project and research. This was primarily due to initially unplanned early expert discussions or uncertainties in the requirements as the user-centred design process was still being prepared. These key events are overlaid with the effective project plan as shown in \autoref{fig:implementation-timeline-key-events}. These three green key events are the most influential key events.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\linewidth]{implementation-timeline-key-events.png}
  \caption{The key events overlaid on the effective project schedule as illustrated in \autoref{fig:implementation-timeline}, with the most influential events coloured green.}
  \label{fig:implementation-timeline-key-events}
\end{figure}

% empirical software engineering done in the case study based on a user-centred design process via user interviews, expert interviews, internal group discussions, and ongoing literature research.
% MENTION analysis paralysis

\section{Key events while building a N/CI}
\label{chapter4-key-events}

This section goes over each key event as shown in \autoref{fig:implementation-timeline-key-events} and discusses why it happened and was critical to the project's success. The following outline of the key events is not chronologically described but starts with the most significant ones.

\subsection{User interview insights}
\label{chapter4-user-interview-insights}

The conduct of user interviews was one of the most significant key events. This process began with developing customer personas based on the sales team's previous experiences with real customers and the planned customer segments targeted by C-level management. In summary, the author does not want to go into too much detail about how the personas were created and how the process went because the focus is on the results based on the user interviews, not on the persona creation process itself. The personas are illustrated in \autoref{fig:personas}, a more descriptive overview of the personas can be found on TABLE lol and a more detailed version is included in \autoref{appendix4-other-documents}.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\linewidth]{personas.png}
  \caption{IDUN's customer personas.}
  \label{fig:personas}
\end{figure}

\begin{table}[ht]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{
>{\columncolor[HTML]{FFFFFF}}l l|l|}
\cline{3-3}
\cellcolor[HTML]{000000}{\color[HTML]{FFFFFF} Persona} &
  \cellcolor[HTML]{000000}{\color[HTML]{FFFFFF} Occupation} &
  \cellcolor[HTML]{000000}{\color[HTML]{FFFFFF} Description} \\ \hline
\multicolumn{1}{|l|}{\cellcolor[HTML]{FFFFFF}\textbf{Alex}} &
  \begin{tabular}[c]{@{}l@{}}Lead,\\ Innovation Management\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Alex works in a large/small company to bring new innovations and technologies into business and\\ product development roadmaps. Alex informs the company's senior management (CTO/CTIO)\\ about new innovations and how they may impact future business and strategic initiatives. Alex\\ has a budget to spend but is supported in decision making by colleagues in R\&D, product\\ development and innovation scouting.\end{tabular} \\ \hline
\multicolumn{1}{|l|}{\cellcolor[HTML]{FFFFFF}\textbf{Noel}} &
  \begin{tabular}[c]{@{}l@{}}PhD,\\ Neuroscientist\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Noel works within large and small organizations to build innovations based on neuroscience and\\ technologies into future products with an outlook of 5+ years. Noel leads a team or group and\\ informs innovation managers such as Alex about new neurotech products and how they may\\ provide new value to customers. Noel has to get approval to start new projects and obtain\\ budgets for larger initiatives. Noel informs key stakeholders in the organization and is supported\\ in decision-making by colleagues in R\&D, engineering teams, and innovation scouting.\end{tabular} \\ \hline
\multicolumn{1}{|l|}{\cellcolor[HTML]{FFFFFF}\textbf{Robbie}} &
  \begin{tabular}[c]{@{}l@{}}Intern,\\ EEG Lab Testing\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Robbie works within a lab and research group, possibly in large or small organizations, either\\ commercial or academic. Robbie often starts from a study protocol developed with or given by\\ Noel, where a test procedure needs to be followed to have consistent data collection methods\\ with different test subjects. The work of Robbie supports the assumptions and study endpoints\\ or goals defined by Noel and neuroscience colleagues. The results may be used in product\\ development or to prepare a research report, white paper, publication, etc. Robbie works\\ hand-on in the lab, knows how to put on a wet-electrode EEG system, looks at raw signals\\ and understands if the data is being collected correctly. Robbie debugs test setups when things\\ are not running correctly, may process results with scripts and is familiar with lab setups like\\ sleep labs. Robbie can also process the study results, put them together for interpretation\\ together with Noel and support technical details that may (but are not often) communicated\\ to Alex.\end{tabular} \\ \hline
\multicolumn{1}{|l|}{\cellcolor[HTML]{FFFFFF}\textbf{Evan}} &
  R\&D, App Developer &
  \begin{tabular}[c]{@{}l@{}}Evan works within large and small organizations to build engineered solutions based on a\\ toolkit of code and hardware technologies that form the foundations of future products with\\ an outlook of 1-5 years. Evan works in a team or as part of a technical group and works with\\ smart people like Noel. Evan doesn’t have a background in neuroscience but knows about\\ electrical signals and how to build prototypes and demos. Evan needs the approval to spend\\ more than 500 CHF on anything. Evan helps Noel to give great presentations to stakeholders\\ in the organization but is generally not in strategy discussion. Evan is supported in SCRUM\\ and development tasks by colleagues in the R\&D and engineering teams.\end{tabular} \\ \hline
\end{tabular}%
}
  \vspace{10pt}
  \caption{Overview of IDUN's customer personas.}
  \vspace{-5pt}
\label{tab:customer-personas}
\end{table}

People were then chosen to represent the personas as accurately as possible. The IDUN staff scoured their network to accomplish this. Finally, the author compiled a list of twenty individuals. Seven people were chosen from this list and invited for separate interviews. The interview outline was planned in collaboration with IDUN's product manager and an industry UX expert, Laura Bendixen, who works as a UX designer at Blick.ch. The author completed the outline based on Laura's expertise with previously conducted user interview sessions, which can be found in \autoref{appendix1-user-interviews}. All user interviews were conducted remotely and lasted no more than 1.5 hours. During the interviews, insights were transcribed on post-its. People working with BCIs or EEG were interviewed, as were PhD students working in research labs, developers who, e.g. had never worked with BCIs or had extensive experience building even own BCI software, and business enablers from companies responsible, e.g. for BCI-based accessibility. More details about the chosen individual interviewees can be found in \autoref{appendix1-user-interviews}.

The questions were non-leading and open-ended, with the primary goal of allowing interviewees to express themselves, capture their perceptions of the BCI industry, and introduce IDUN's vision and mission upfront. The goal was to determine what software offerings a mass-market BCI-software device would need to provide, such as convincing developers who have never worked with BCI to include neuro-enhanced features or convincing researchers to use IDUN's NIP in their research. The questions and answers were all about different things. More technically oriented people inquired about speed, performance, and privacy concerns (ergo, more production-readiness thinking), whereas researchers inquired about signal quality, the ability to synchronise with other data streams, and access to raw data (more general applicability thinking). After the last user interview, all post-its were compiled, similar insights were grouped, and the product manager, as well as the author, categorised the most important insights into a list:

\begin{itemize}
  \item \textbf{There are two prominent use cases: using the NIP for research and developing an end-user-facing app.} These are two critical distinctions. Researchers would use the NIP to learn about the brain, such as through simple-setup remote experiments or real-life long-term experiments outside of laboratories. The NIP would, in such a use case, still be used in production, but not to potentially thousands or millions of users in an app intended for end users. The company or developer using the NIP would have physical access to the hardware in the research use case because they would most likely buy one or more devices and hold them in their repertoire. In contrast, companies targeting production use cases would ship the devices as, e.g. white-labelled hardware through their own or 3rd-party channels. Perhaps we can even go so far as to say that because IDUN distributes the device so well, companies and developers do not need to sell the device themselves but can assume that users own such headphones and then access the brain API such as e.g. today's developers can assume that every end-user has GPS access in their smartphone.
  \item \textbf{Visual demos that are easily accessible for someone owning the hardware are essential for all personas, most notably an Alex.} A visual and simple demo should demonstrate what one can do with the NIP from IDUN and inspire others to conduct research, build apps or enable business and opportunities. These demos need to explain to the different personas the different benefits; next to that, the end-user should be able to try out the demos to see the benefits of BCI-enhanced technologies. People like Evan should be able to adapt demos with their codes to create their own versions of them.
  \item \textbf{The user of the NIP needs to have as low-level control over the data flow and classification as possible} but also with an option for less technical users to use it and build things, similar to, e.g. AWS: AWS itself is only an API to use cloud IT resources, but they also have the AWS Console app to build everything via a GUI instead only via the API. What is very important here is that people such as, e.g. Noels need to know precisely what algorithms were used or the methodologies for specific classifiers to justify them and integrate them into their research. They do not, in most instances, actually need raw data access, as plotting functionality would also be enough; therefore, IDUN's NIP should have some functionalities to plot and visualise data.
  \item \textbf{In order to ease the use of the GUI and the API of the NIP, IDUN needs to provide, next to sufficient documentation, comprehensive libraries for specific environments} that make the unobtrusive implementation of the NIP easier. Such as e.g. providing a client-side JavaScript package that is lean and easy to use that can be integrated into existing apps. Examples for such code integration would also need to be provided by IDUN so that people like Evan can easily adjust them and more quickly start integrating them into their apps or research codebases. The personas would need to abstract the brand IDUN as much as possible, e.g. Intel is doing with their Intel-inside ingredient strategy \citep{intel_ingredient_nodate}.
  \item \textbf{End-users need control over their data so that other companies accessing the NIP API cannot collect their data} on their servers and do everything they want. Imagine if, e.g. the operating system layer of one's smartphone would not offer an opt-in mechanism for the cameras, then 3rd-party developers could install spyware and record without the user permits it. When, e.g. users start to use multiple apps with a NIP integration, there needs to be some way to control the opt-in and data access without the app developers having any saying on the decisions. There needs to be a technical limitation from the side of the hardware or the cloud to ensure user privacy and data security for end-users.
  \item \textbf{Researchers are very interested in the raw EEG data and the synchronisation possibilities with specific protocols} such as LSL to combine, e.g. a heart rate sensor with the EEG collected from IDUN's hardware. The NIP software offering needs to give enough freedom to combine the data without letting all other collected data flow into the NIP from IDUN. This means that the NIP should be able to collect, transform and, most importantly, label data in correlation with other data streams with a local option to satisfy researchers like Noel.
\end{itemize}

These insights were critical in determining that there must be sufficient freedom for raw data research without releasing raw data into mass market production environments to protect end-user privacy. As a result, an opt-in mechanism outside of third-party ecosystems is required. A library that can be implemented in end-user apps and connects directly to the hardware without the need to download a companion app from IDUN itself is also required. This library should allow researchers to access it locally and, e.g. use their preferred protocols to synchronise tags and labels with other data streams. Nonetheless, IDUN's NIP should once again provide some control over how much raw data can be collected and restrict access if, e.g. the proposed research project or experiment time frame is exceeded. Furthermore, additional NIP functions should be added to visualise easy-to-use demos for all personas, as well as a way to use and control the NIP without having to write code, but with enough flexibility and transparency that there is trust in the system and even advanced users can work with a visual tool instead of code.

\subsection{Invention of N/CI}
\label{chapter4-invention-of-nci}

The insights from the user interviews, combined with the ongoing research on B/CI and remote BCI mentioned in the introduction chapter, were key to realising the novelty of this new interdisciplinary approach to developing a production-grade and mass-market BCI software system running in the cloud and targeting the general population via general applicability. It is important to note that the realisation that such a system had not yet been defined in research only emerged in the seventh sprint. The findings from the user interviews were primarily in the direction of the N/CI definition, while the literature review was primarily in the direction of distinguishing between existing research and definitions.

Once a first draft of the definition was written down, the research and separation of work packages could be more easily tackled and explored due to a better understanding of what was new and unexplored. At the time of the end of the seventh sprint, the author's goal was to develop further and define the definition and motivation in the form of the last part of the context chapter of this thesis which had to be introduced first before moving on to the methodology and implementation chapters. That is, without a broad understanding, the motivation and the general definition would be difficult to understand.

\subsection{Web-native approach}
\label{chapter4-web-first-approach}

Before Sprint 6, there were some ideas about future architecture roadmaps designed by the author of this thesis, as shown on \autoref{fig:architecture-roadmap}.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\linewidth]{architecture-roadmap.png}
  \caption{Original architecture roadmap of IDUN's NIP.}
  \label{fig:architecture-roadmap}
\end{figure}

The initial architecture roadmap was part of the project's initial phase to define the key technical requirements and constraints and show how the NIP software stack would move from a high latency system to a low latency system. More details on the latency aspects are discussed later in this thesis. Nonetheless, one aspect of this old architecture roadmap was that IDUN would continue to maintain and develop the physical hardware network bridge and eventually port it to end-user devices as a companion app. However, just before Sprint 6, the author stumbled upon the work of \citeauthor{flynn_brainsplay_nodate} of the BCI platform called Brains at Play and its use of Web Bluetooth, which is a new and experimental API for browsers that allows websites to connect directly to a Bluetooth Low Energy (BLE) device. The Brains at Play platform is a hardware-independent BCI software platform with similar goals to Neuromore Studio. The main difference is that they offer their app as a web app; therefore, everything runs in the browser without downloading additional software. The author contacted Garrett Flynn, one of the founding partners, and discussed the implications and findings of using Web Bluetooth, e.g. EEG data such as that from IDUN's sensor (later, Garrett Flynn was also invited to the user interviews as one of the persona representatives for Evan). Garrett Flynn's findings were entirely positive, and he strongly recommended working with the API as it makes deploying a BCI platform much more effortless than deploying applications for any operating system, especially any BLE interface. However, one of the main disadvantages of Web Bluetooth was browser compatibility, as shown in \autoref{fig:can-i-use}.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\linewidth]{can-i-use.png}
  \caption{Browser compatibility overview of Web Bluetooth \citep{caniuse_web_nodate}.}
  \label{fig:can-i-use}
\end{figure}

Nevertheless, IDUN is building a product that aims for an extensive user base in 2-3 years, as can be seen on their roadmap in \autoref{fig:idun-timeline}. This means that browser compatibility could come and ease out over the coming years once browser manufacturers start implementing the API. One problem, however, is that the web Bluetooth API cannot be run in a service worker, making it impossible to run in the background when e.g. the device has its screen locked or another app is currently opened on a smartphone \citep{webbluetoothcg_service_2018}, which is an intermediate problem, even for the upcoming smaller and specific user groups with the current personas. Among a variety of technologies under investigation, the author identified Capacitor, a JavaScript library, to be a suitable candidate for the current use case. It essentially can compile and run web apps as native apps, with the ability to access native APIs \citep{ionic_capacitor_nodate}, such as the camera or, especially important for IDUN, the BLE API \citep{capacitor-community_capacitor-communitybluetooth-_2022}. Developers can use Capacitor to write BLE code with the same interface as Web Bluetooth, compile the code and run the applications on native devices with background functionality.

After further research, as shown in \autoref{appendix4-other-documents}, almost the entire Sprint 6 was spent evaluating the possibility of using Web Bluetooth for IDUN's NIP. At the end of the sprint, a working PoC SPA was created with an iOS and Android build that fulfilled all needs in terms of developer experience, the latency of the EEG signal from the device to a visualisation plot and the power consumption of lower-end smartphones. Following this, the author proposed to change the original architecture roadmap as depicted on \autoref{fig:architecture-roadmap} and skip the first two steps and go directly to step 3 in order to accelerate the development pace and enable greater market maturity for IDUN's NIP as soon as the end of 2022.

The use of a web app, combined with the use of modern APIs and the compilation of the app for mobile applications when compatibility is not guaranteed, is called a web-native approach \citep{ionic_web_nodate}. Besides the time saved by not having to develop platform-specific apps but using a single code base, this approach also has the advantage that a library that abstracts the logic of connecting a BLE device such as the IDUN device can already be created into a single installable unit, e.g. in the form of an NPM package. This library can be implemented in end-user apps and connects directly to the hardware without the need to download a companion app from IDUN itself, and is one of the solutions to the findings from the user interviews. The time saved with a web-native approach allowed IDUN to already focus on creating such a library and using it in their web app, which would be the console or GUI as in the AWS example, allowing dogfooding for IDUN's own software offerings and eliminating preliminary issues before releasing the library to the public \citep{techopedia_what_2016}.

\subsection{Python to WebAssembly}
\label{chapter4-python-to-webassembly}

Another key event during the ten sprints took place about two sprints before evaluating the web-native approach. The idea was that, as mentioned in \autoref{chapter3-software-and-tools}, when it comes to how important and necessary the Python ecosystem is for IDUN and external people as presented in the personas, it might be possible to create Python code for specific neural signal data processing, compile it to WebAssembly, a low-byte compilation target for high-level languages that run mainly in the browser, and then use it in web applications such as, e.g. the GUI application of IDUN's NIP. Sprint 5 evaluated compiling Python into WebAssembly, which seemed promising at first but turned out to be too far away from today's possibilities. There is an interesting open source project called RustPython, a Python interpreter written in Rust that allows the interpreted code to be compiled in WebAssembly. However, the project's maturity is currently unsuitable for production, as the maintainers even mention it \citep{noauthor_rustpython_2022}.

Another option would be to use Pyodide; the CPython interpreter ported to WebAssembly \citep{noauthor_pyodide_2022}. Apart from the fact that the creation of a web application would be drastically more significant if a complete Python interpreter were sent to the browser, this interpreter also does currently not have the functionality to add additional Python packages apart from the standard library, e.g. PyPi, which makes it easy to build vanilla Python on top of WebAssembly codebases, but not with custom packages installed, such as machine learning packages needed for EEG classifiers. The only options left were to develop an own Python to WebAssembly compiler, contribute to the two open source projects, or give up the task of embedding Python code in a web application such as IDUN's GUI application to interact with NIP's API. The latter was chosen because it was still too early, immature and time-consuming, as the results of Sprint 5 showed.

\subsection{Kubernetes and Fargate}
\label{chapter4-kubernetes-and-aws-fargate}

One of the first technical decisions the author of this thesis made was which technology to use for creating backends for an n-tier\footnote{The term n-tier refers to an architecture design pattern where the logic of presentation, application processing, and data management are decoupled from each other, as in the case of, e.g. multiple microservices.} system like IDUN's NIP. The use of a microservice approach was already given by the fact that a polyglot backend was needed, such as Python for data-heavy tasks and TypeScript for real-time and API-specific tasks due to the maturity in the previously mentioned examples of each language. If one decides to take a microservice approach, one can still debate whether to proceed with serverless functions instead of hosting container images. Given the requirement to use AWS mentioned in \autoref{chapter3-software-and-tools}, the only way to host serverless functions was to use AWS Lambda. AWS Lambda was already used in the previous PoC version of the software system at IDUN and did not work as well as in cases where, for example, batch processing of previously collected data would exceed the maximum computation time or CPU limit of AWS Lambda. This, coupled with the cumbersome aspect of handling dozens if not hundreds of serverless functions and managing the entire "cluster" of multiple functions and their versions and endpoints, led to the decision not to use Lambda for the most essential and critical parts of the backend in the author's experience so far.

Building microservices not with serverless functions on AWS, has multiple solutions: the most prominent ones are utilising Kubernetes via AWS Elastic Kubernetes Service (EKS) or AWS Fargate, which is a serverless and easier-to-use version of Kubernetes \citep{amazon_web_services_inc_serverless_nodate}. The author consulted cloud experts in the very first sprints from the company Nuvibit to guide the decision. The author himself is not experienced in Kubernetes and would need to learn many ways to implement a Kubernetes cluster, which was one of the items mentioned to avoid mentioned in \autoref{chapter3-software-and-tools}. Nuvibit recommended going with AWS Fargate since it is similar to Kubernetes but abstracts most things away to concentrate on adding business logic rather than handling overheads coming with introducing a Kubernetes cluster. Fargate is per se also serverless, making it cheaper for a product with hard-to-estimate usage such as IDUN's NIP in the beginning but still gives enough flexibility in specifying the underlying hardware for computationally heavier tasks that, e.g. would exceed AWS Lambda. As soon as IDUN goes toward utilising large-scale deep learning models that utilise specific GPU units, Fargate will come to its limits since specifying GPU tasks is impossible \citep{aws_aws_2019}. One way or another, this decision will have to be reconsidered in the future to avoid a long-term commitment to one provider such as AWS and to the increasing investments of Kubernetes from several cloud providers.

\subsection{Kafka and Kinesis}
\label{chapter4-kafka-aws-kinesis}

Another early technical decision, made with the help of expert interviews, was which streaming technology to use. As with many things in software, there are hundreds, if not thousands, of ways to solve a problem, such as streaming text-based data like the EEG data from IDUN's device over the internet to the cloud. Initially developed by LinkedIn, Apache Kafka is a very prominent technology for such a use case. It is battle-tested, used in production by large technology companies \citep{apache_apache_nodate} and well maintained by an active community \citep{noauthor_apache_2022}. However, similar to Kubernetes, it comes with much overhead, and the author himself has no experience with Kafka, so he would have to learn everything from scratch. Another option is to use AWS Kinesis, a service AWS provides to process data streams over the cloud, as Kafka does, but without the overhead of managing the Kafka instances themselves. AWS Kinesis allows streams to be replayed, restored and sent to an AWS Fargate cluster, e.g. real-time processing of the data, or data to be stored securely in storage systems such as AWS Simple Storage Service (S3) as shown on \autoref{fig:aws-kinesis}. An important aspect is that the data source can also come from a WebSocket stream, which will be addressed in the next section. However, the decision for Kinesis was relatively easy, as the reasoning was similar to that between Kubernetes and AWS Fargate. The decision was also supported by the experience and opinion of the cloud experts at Nuvibit.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\linewidth]{aws-kinesis.png}
  \caption{Example use-case architecture of AWS Kinesis \citep{amazon_web_services_inc_amazon_nodate}.}
  \label{fig:aws-kinesis}
\end{figure}

\subsection{MQTT and WebSocket}
\label{chapter4-mqtt-and-websocket}

As previously stated, a decision had to be made regarding the technology to transfer data from a physical device, such as IDUN's EEG sensor hardware, to the cloud. Previous engineers at IDUN used MQTT to stream data from the hardware directly to the web app, as mentioned in the list of bugs and flaws in \autoref{chapter3-derivation-of-the-case-study}. MQTT is not well suited to sending high-frequency data in real-time, such as EEG, and it is geared toward lower-power IoT devices rather than, say, a computer or smartphone to which the IDUN device would be connected. As a result, the decision to use something else had to be considered. Another option is to use WebSocket, which is designed for high-frequency updates that can be updated in real-time in both directions. IDUN would want to use a high-frequency protocol because, e.g. HTTP can only handle about ten requests per second, whereas e.g. WebSocket can handle nearly 4000 requests in the same amount of time. The main reason for this significant difference is that, e.g. the browser limits the number of concurrent HTTP connections, whereas a WebSocket connection has no limit on the number of messages it can send or receive \citep{luecke_http_2018}. Sending EEG data at a frequency rate of 250 samples per second from the IDUN hardware and receiving multiple classification responses from the cloud based on the chosen classification necessitates more than ten requests per second.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.75\linewidth]{firmware-engineers.jpeg}
  \caption{Photo of an internal group discussion with the firmware engineers from IDUN.}
  \label{fig:firmware-engineers}
\end{figure}

WebSocket also integrates easily with the earlier technology decision for AWS Kinesis, as Kinesis can subscribe to an API gateway service from AWS that can be used to build Representational State Transfer (REST) APIs (more on this in \autoref{chapter5-example-architecture-of-a-nci}). An internal group discussion with firmware engineers for IDUN's hardware was organised to validate this decision, as shown on \autoref{fig:firmware-engineers}, as it was too BCI specific to ask, e.g. Nuvibit's cloud engineers. The alignment with the firmware roadmap and its interface, which would be necessary for, e.g. the BLE library that would consume it as mentioned in \autoref{chapter4-web-first-approach} was key to the success of building an example N/CI at IDUN.

\subsection{IaC with Terraform}
\label{chapter4-iac-with-terraform}

As mentioned in the list of bugs and flaws in \autoref{chapter3-derivation-of-the-case-study}, AWS Amplify took over handling IaC via AWS CloudFormation. When creating the new version of the system without Amplify, the author was now free to choose which IaC technology to use. The author could have again used AWS CloudFormation, but without AWS Amplify, or he could have used the more modern AWS Cloud Development Kit (CDK), which provides specific syntax in specific languages for building IaC \citep{amazon_web_services_inc_aws_nodate}. However, there is a very well-known technology in the industry called Terraform, an open source and YAML-based tool from the company HashiCorp, which is similar to, e.g. AWS CloudFormation's JSON syntax in declaratively describing IT resources in the cloud, with the big difference that it is cloud agnostic, meaning that Terraform can be used to build and deploy IT resources not only on AWS but on any cloud provider currently supported by HashiCorp \citep{hashicorp_browse_nodate}. Nevertheless, Terraform is currently still in beta, which is usually not a very good sign for production readiness; nonetheless, Terraform is used in production by various large tech companies \citep{stackshare_why_nodate}. Again, Nuvibit's cloud experts were consulted to decide which IaC tool to use, as the author had no experience with, e.g. AWS' CDK or AWS CloudFormation. As a result of the expert interview with Nuvibit, it was clear that Terraform was the right way forward for IDUN, as future multi-cloud setups or other IT resources can also be handled via Terraform e.g. Auth0 authentication tenant setups, GitHub organisation setups via IaC and more. In addition, the author already had experience with Terraform, which was another argument for using Terraform.

The decision to use Terraform was also made relatively early in the process and laid the foundation for every infrastructure built after that to be based on Terraform code. Tools like Infracost and tfsec were set up as part of the bootstrapping project stages in order to assure quality in the form of linting over IaC code via tfsec in continuous integration and continuous delivery (CI/CD) pipelines or calculating price estimations based on IaC code as soon as writing it in the editor via the Infracost add-on.

\subsection{Python SDK}
\label{chapter4-python-sdk}

The key event called Python SDK on \autoref{fig:implementation-timeline-key-events} happened quite late in the process but was one of the important events. It describes the realisation of creating a public and a private Python library mainly for the Noel persona. The realisation followed internal group discussions with the neuroscience team at IDUN. Before these internal group discussions, the author assumed that a GUI application such as the console application of IDUN's NIP in combination with an API and a client-side library would suffice for applications created by, e.g. Evans. However, as mentioned in the last point of the user interviews listed in \autoref{chapter4-user-interview-insights}, there would need to be a way to control the EEG data collected by IDUN's device and synchronise it locally with other data sources, such as heart rate data, without having to send the data to the cloud\footnote{The reason for this is that one cannot synchronise data sufficiently over an internet network due to latency problems or time drifts.}. Noels would use a GUI application like the idea for the console application of IDUN's NIP. However, they would nonetheless still like to have low-level control of the data, e.g. to include it in PsychoPy experiment scripts or to connect the data via an LSL stream, e.g. to a reference EEG device to compare EEG signals (which is, e.g. particularly important for IDUN's internal researchers). For this, they would need a library that allows them to connect to the device without an app, if possible only for research purposes. After the internal group discussions with the neuroscience department, the author proposed building an SDK that precisely does this.

Parts of this SDK can also be made public as part of the software offerings from IDUN, such as connecting to a device for limited research purposes or to, e.g. visualise plots specifically made for IDUN's EEG data as also mentioned as one of the user interview insights in \autoref{chapter4-user-interview-insights}. An internal SDK version of this can e.g. be used to, e.g. include raw data pre-processing pipelines and feature extraction as preparation for machine learning classifiers which are all part of IDUN's provided intellectual property and should not be made public. Nonetheless, this internal SDK can be used in the neuroscience team and production, e.g. Python microservices that process data in real-time. The reason why one would want to have that is that if, e.g. a data scientist creates a new script for processing EEG data that can be used, e.g. demos, used in research and even in production for an API endpoint that IDUN sells, then they all would need to have the exact source of the code. An internal PyPi Python package for the SDK is the solution to that. This realisation came pretty late and is, as of writing, still ongoing.

\nomenclature[ble]{BLE}{Bluetooth Low Energy}
\nomenclature[eks]{EKS}{Elastic Kubernetes Service}
\nomenclature[s3]{s3}{Simple Storage Service}
\nomenclature[rest]{REST}{Representational state transfer}
\nomenclature[cdk]{CDK}{Cloud Development Kit}
\nomenclature[cicd]{CI/CD}{Continuous integration and continuous delivery}
